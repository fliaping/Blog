---
title: "大模型系列文章-大模型为什么有效"
date: 2023-08-15T10:56:35+08:00
draft: true
categories: ["AI之遥"] # Developer AI之遥 科幻Fans 智慧之光 星云尘埃 酷cool玩
slug: "the-introduce-of-linux-audio-system-alsa"
tags: ["chagpt"]
author: "Payne Xu"
---
# 引言

## 什么是智能？

人类公认的智能体就是人类自己，人类智能有以下特点：

- 学习能力: 能够从经验中学习并适应新的环境。
- 理解与推理: 能够理解复杂的信息和进行逻辑推断。
- 解决问题: 面对挑战或问题时，能够找到有效的解决方案。
- 自主决策: 在没有外部帮助的情况下，基于信息和经验做出决策。
- 语言处理: 理解和产生语言，进行有效的沟通。
- 创造性: 能够创新或想出新的解决方案

那么其他动物例如猫狗、果蝇、蜜蜂，是否是有智能的？和常说的人类智能有一定区别，这些动物在某些方面匹配智能的一些特点，例如：狗可以被训练来识别命令、找到物品，甚至进行某些任务；而猫则在捕猎和地盘卫士方面表现出复杂的策略；果蝇可以被训练识别特定的气味并与之关联特定的奖励或惩罚；蜜蜂能够进行简单的数量识别和分类。和人类的智能相比其他动物的智能都相对低级。

## 人类如何产生智能的？

对于这个问题，目前的科学水平还无法很好的回答，从当前的认知来讲，人类智能的产生可以从神经科学、生物学、心理学、进化学和其他多个领域来进行解释，这里分享下个人的理解：

1. 硬件基础：人类的大脑有比较复杂的结构，有庞大的神经网络，相当于有了硬件基础。一些无脑生物，例如单细胞生物就只有本能的反应，不会产生智能的表现。
2. 现实需求：人类的远古祖先学会使用工具来适应环境和获取食物，这需要更高级的认知和解决问题的能力。包括为了生存的集体合作，催生了复杂的语言和文化的形成。
3. 软件实现：在人类社会生存，需要不断适应社会环境，不断学习，传承文化和知识，人类的智能可以认为不是个体的成就，应该是群体的智慧，通过学习掌握后表现为个体的智能。
4. 优化迭代：创造性是人类智能的推进剂，情感是人类智能的稳定剂，通过这两种形式让人类智能不断进度，达到更高的高度。

# 大脑的原理

我们先从大脑的原理出发，看看智能需要什么样的硬件，当然当前的研究结论并不一定是完全正确的。

## 基本结构

1. **大脑皮层 (Cerebral Cortex)** ：是大脑的外部层，主要由灰质组成。它是人类的思维、知觉、决策和行动的中心。大脑皮层可以进一步分为四个叶：

* 前额叶 (Frontal Lobe)：与决策、规划、情绪和行为控制有关。
* 顶叶 (Parietal Lobe)：处理触觉信息，如触摸、温度和痛感。
* 枕叶 (Occipital Lobe)：处理视觉信息。
* 颞叶 (Temporal Lobe)：涉及听觉、记忆和某些方面的情感处理。

1. **基底核 (Basal Ganglia)** ：这是一组深入大脑的核，与运动控制、学习和情绪有关。
2. **丘脑 (Thalamus)** ：它是大脑的主要传感信息中继站，负责将大部分传感器输入信息发送到适当的大脑皮层区域。
3. **下丘脑 (Hypothalamus)** ：是调节体温、饥饿、渴和其他基本生理功能的中心。它也与许多情感反应和驱动力有关。
4. **海马体 (Hippocampus)** ：与记忆形成、组织和存储有关。
5. **杏仁核 (Amygdala)** ：涉及情感处理，特别是与恐惧和愉悦有关的反应。
6. **脑干 (Brainstem)** ：包括中脑、桥脑和延脑。它连接大脑和脊髓，并控制许多基本的生命维持功能，如呼吸、心跳和血压。
7. **小脑 (Cerebellum)** ：主要与协调运动、平衡和身体位置感知有关。

![Human Brain](../../uploads/image.png)

## 神经网络

神经网络是各种动物大脑中的基本结构，神经网络由许多神经元连接组成，其中神经元的结构如下

![神经元的结构](../../uploads/image-2.png)


**突触 (Synapses)：** 突触是神经元之间的连接点，使神经元能够传递信号给其他神经元。
当一个神经元兴奋时，它通过突触释放化学物质（神经递质）来激活或抑制另一个神经元。
大脑中有数万亿的突触，为神经元提供了丰富的连接网络。

**神经递质 (Neurotransmitters)：** 神经递质是在神经元之间传递信号的化学物质。
常见的神经递质包括多巴胺、乙酰胆碱、5-羟色胺、GABA和谷氨酸等。
这些化学物质对大脑功能和心理状态（如情绪、认知和行为）有着重要的影响。

**轴突 (Axons) 和 树突 (Dendrites)：** 轴突是神经元的“发送”部分，用于将电信号传递到其他神经元或肌肉。
树突是神经元的“接收”部分，它们接收来自其他神经元的信号。

**髓鞘 (Myelin Sheath)：** 髓鞘是一种包裹在多数轴突周围的脂肪质材料，其功能是加速电信号的传播。


人体大脑中大约有860亿神经元，每个神经元每秒能够产生高达一千次的电脉冲，并通过突触可以和其他上千个神经元连接，总的突触数量在百万亿级别，下图是一个大脑可视化项目【H01】数据集，可以看到模拟出来的3D图形中密密麻麻的神经网络连接。

![神经网络的连接](../../uploads/image-1.png)

# AI神经网络

对比前文提到的智能的定义，对比当今的AI技术

- 学习能力: 通过模型预训练，将海量的数据内化到千亿级的参数中
- 理解与推理: 从ChatGPT 3.5开始，AI表现出来优秀的含义理解能力和逻辑推理能力
- 解决问题: ChatGPT给的答案就是解决问题的能力，但答案正确性，解决方案的有效性仍是一个大的问题
- 自主决策: 初级阶段，AI自主决策的风险比较高，有个人工智能小镇的一个实验用了自主决策的能力
- 语言处理: 这一方面是ChatGPT的拿手好戏
- 创造性：生成式AI就是机器创造出不存在的东西，虽然和已有的比较像，但绝对不是完全一样。

从上面的情况看人类智能的定义，以ChatGPT4的效果看，很多方面已经达到了非常接近人的水平，但有些方面还需要提高。

## 从函数出发

在数学上函数是一个输入输出系统，数字输入，数字输出
![函数](../../uploads/image-3.png)

例如初中学习的三角函数，解方程，这些都是前人已经发现的函数，我们由已知函数函数去求解

![三角函数Cos(x)](../../uploads/image-4.png)

如果是我们知道在(x,y)平面坐标系的一系列的点集，求对于(x,y)关系的函数，我们怎么做？高中数学也有类似的题，我们拿点集在二维坐标上标记，然后将点连起来，看跟我们学过的哪个函数比较像，就用这个函数套进来就行了。

![点集到函数](../../uploads/image-5.png)

这时我们做的就是 **函数逼近** ，对于未知的函数f近似已知函数T，即 `f(x)≈T(x)`，但是对于复杂的场景，例如：

![复杂的分类点集](../../uploads/image-10.png)

要求我们找到一个函数，输入点坐标，输出点颜色，`f(x,y)=z` x,y是输入，z是输出，这个函数就不是简简单单一个公式就可以表示的，确切说人类很难找到一个标准的函数去描述它们。

![一只小猫](../../uploads/image-9.png)

再例如我们平时写的代码也是函数，各种函数叠加在一起形成系统，系统整体可以看做一个大函数，函数的定义是将人类的形式逻辑用机器语言表达出来。但是如果让我们写代码识别图片中的小猫，如果还按照形式逻辑来写代码识别，几乎无法实现。


## 通用函数逼近器

如果我们有一个目标函数，如图，但我们并不知道这个函数的定义，我们能否有一个通用的方法模拟出该函数？

![一个目标函数](../../uploads/image-11.png)

如果没有在数学领域有深入研究，这个事情还是比较难的，从常识来讲看起来是有一个简单的公式来描述的，但可惜我们不知道，这里用这个曲线只是为了便于说明，那么回到正题如何模拟这样一个函数？

我们知道一些简单的线性函数，例如`y=wx+b`，其中w是权重，b是偏置，这两个参数的变化会对应函数图像的变化
![线性函数变化](../../uploads/linear-function-plot.gif)

能否用简单的线性函数模拟呢，我们都会过微积分，也知道分而治之的理念，那么将曲线分割为一段段的直线，就可以近似模拟出来，如下图：
![直线模拟目标函数](../../uploads/image-12.png)

上面的模拟如何用函数表示出来？我们对每一段直线测量两个点，代入`y=wx+b`就能算出每个直线度的w和b值如下：
![分段线性函数](../../uploads/image-13.png)

如何把分开的函数合并为一个？如果把上面的函数全部画在一个图上，就是六条交叉的直线，要拟合目标函数还需要限定每个函数的左右范围，我们当然可以通过限定x区间使用不同韩式方式

$$
\left \{ \begin{array}{l} 
  N_{0}(x),   x \in \left (r1,r2 \right]\\ 
  N_{1}(x),   x \in \left (r2,r3 \right]\\  
  N_{2}(x),   x \in \left (r3,r4 \right]\\ 
  N_{3}(x),   x \in \left (r4,r5 \right]\\  
  N_{4}(x),   x \in \left (r5,r6 \right]\\
  N_{5}(x),   x \in \left (r6,r7 \right]\\     
\end{array}  \right. 
$$

当然这是一种省事的方式，但计算机来解这个题的话，如何计算出每个函数的权重(w)和偏移(b)以及每个函数的作用区间r1...rn?

这里引入神经网络，我们定义一个神经元就是简单的线性函数`y=wx+b`,神经元计算时就是把输入的x代入，计算出输出y，很多神经元连接在一起，组成一个简单的神经网络，在数学上表示就是把各个神经元的函数通过运算连接起来，这里假设我们已经知道了每个神经元中参数，如果是简单的加减乘除运算，线性函数叠加线性函数依然是线性函数.

![线性函数叠加仍是线性](../../uploads/image-14.png)

为了叠加出非线性函数，可以对每个神经元应用激活函数，激活函数顾名思义可以限定在某些条件下激活，这就可以将神经元从线性函数转变为非线性的，例如常用的ReLU函数，非常简单 $ReLU(x)=MAX(x,0)$ ,叠加之后神经元的函数变为 $N(x)=MAX(wx+b,0)$

![relu-activation-function](../../uploads/relu-activation-function.gif)

这样N个非线性神经元叠加就可以产生非线性的整体函数，通过已知数据集的代入，就可以修改每个神经元的参数，经过非常多尝试后所有的数据集都能匹配这个神经网络，于是这个神经网络就是对已知数据的模拟。

![神经元叠加](../../uploads/neuron-overlay.gif)

前面讨论的神经元比较简单，只有一维变量（一元一次方程），在更复杂的问题中，输入数据是多维的，例如文字、图片、语音，那么多维神经元可以简单表示为

$$
N(x_{1},x_{1},...,x_{n})=w_{1}x_{1}+w_{2}x_{2}+...w_{n}x_{n}+b
$$

## 可视化训练

我们通过可视化的工具[Tensor-Playground](https://playground.tensorflow.org/) 可以自己上手体验下神经网络的学习过程。

![Demo](../../uploads/tensor-playground-capture-2023-7-16.gif)

![palyground-area](../../uploads/image-15.png)



# 人工概率系统

前面从函数出发，用一个简单的数学示例讲了神经网络是通用的函数逼近器。本节主要在应用的角度，看看神经网络如何有效解决实际的问题。

## 世界的概率性


## 频率与分布

## 理解与推理

ChatGPT，基于GPT系列模型，模拟推理能力的核心机制是基于其训练过程和Transformer架构的特性。以下是几个关键点来解释其模拟推理的方式：

1. 大量训练数据：ChatGPT在训练时接触了大量的文本数据，这些数据包括了各种逻辑推理、论证和结论。因此，当它遇到一个需要逻辑推理的问题时，它可以生成一个回答，这个回答反映了它在训练数据中看到的模式。

2. 注意力机制：GPT模型中的注意力机制使得模型能够“关注”输入文本中的关键部分。这意味着，当提供一个问题和上下文时，模型可以根据上下文和问题的重要性进行权衡，从而生成一个合适的回答。

3. 上下文理解：GPT模型有能力考虑前面的文本来为当前的问题提供答案。这意味着，如果你给它一个逻辑推理的问题，它会考虑问题的上下文来生成一个答案。

4. 统计关联：GPT不是通过真实的逻辑进程来“推理”的。相反，它根据在训练数据中看到的统计关联来生成答案。例如，如果它在训练数据中经常看到两个概念一起出现，当其中一个概念在问题中出现时，它可能会在答案中引用另一个概念。

5. 生成式能力：GPT是一个生成式模型，这意味着它可以生成连贯和结构化的文本。这使得它的答案看起来像是经过逻辑推理的结果，尽管这只是基于模型在数据中学到的模式。

总之，ChatGPT模拟推理能力的方式主要是基于它在大量文本数据中学到的模式和结构，以及它的架构特性，如注意力机制。然而，这种“推理”是基于统计学习和模式匹配的，而不是真正的逻辑推理。

# Transformer与GPT


# AGI是否会产生？

# 参考内容

- [What Is ChatGPT Doing … and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)
- [AI有逻辑思维与创造力吗？AI的弱点和发展](https://www.bilibili.com/video/BV1PW4y1p7gX)
- [为什么神经网络可以学习几乎任何东西？](https://www.bilibili.com/video/BV148411c7LQ/)
- [人工神经网络是否模拟了人类大脑？](https://cloud.tencent.com/developer/article/1086037)
- [Tensorflow Playground 讲解](https://juejin.cn/post/6844904200988540942)
- [李沐 - Transformer论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1pu411o7BE)
- [李沐 -  GPT，GPT-2，GPT-3 论文精读【论文精读】](https://www.bilibili.com/video/BV1AF411b7xQ)


